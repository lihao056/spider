#### 3.大型爬取商品数据

​	我们想使用爬虫抓取目标的数据，需要通过解析网页来获取。

##### 3.1 观察页面特征和解析数据

###### 3.1.1 解释页面

​	实现爬虫的第一步是观察页面特征，例如我们想爬取某些数据，我们需要知道如何到达该位置，应添加什么参数等等，所以先通过浏览器查看爬取路径。

​	另外，由于json数据格式是一个较好查询的格式，所以尝试爬取手机端的网页，因为其都为Json格式。

​	首先科普一下网页的构造，本人对网页也不熟，只是当时看的时候稍微了解了一下。可能有错误。

​	1.网页有静态网页和动态网页，静态网页就是ctrl + u出来的html源码，动态网页就是根据当前传入参数后通过数据库查询后返回的网页。

​	2.我们可以通过Google浏览器的开发者工具(F12)中的Network来查看我们请求网页的过程。

​	Network是用来查看各种请求的过程，大佬们称为抓包，网页中的数据就是在各种包中显示的。

![1557313905833](D:\typora\1557313905833.png)

​	可以看到请求了47次，返回了很多包，但是怎么在这么多包中查看要想的信息呢？如2187人喜欢的数字信息是在哪个包里？

​	首先爬虫其实最烦的步骤就是开始找数据的时候，其次我们可以通过Google浏览器的开发者工具Ctrl + F查询。

![1557314323233](D:\typora\1557314323233.png)	

​	在这里查询可以看到有符合的数据，并且告知在哪个包中，方便我们查询。

​	下面进入解析页面的过程。

###### 3.1.2 获取流程

​	首先，我们想获取自由行的产品信息

​	**步骤1.**进入[网页](https://touch.qunar.com)，点击自由行。

![1557314843696](D:\typora\1557314843696.png)

​	**步骤2.**可以看到，有各种类型的包，通过搜索网页内的信息，可以看到，当前数据是在哪个包中。

![1557315093397](D:\typora\1557315093397.png)

​	可以看到是在JS格式中的appHotArrive包中，可以通过headers获取数据

![1557315242339](D:\typora\1557315242339.png)

​	点击上面的搜索，可以看到新的数据，在arriveRecommend包中(JS格式)，另外由于这个是自动运行的，需要删除URL中的callback参数。 

https://touch.dujia.qunar.com/golfz/sight/arriveRecommend?dep=%E6%9D%AD%E5%B7%9E&exclude=&extensionImg=255,175&callback=jsonp_1557317038762_61372

![1557318654272](D:\typora\1557318654272.png)

​	解码后可以看到所需要的参数是城市名称。

![1557315478940](D:\typora\1557315478940.png)

​	**步骤3.**再点击图片，例如丽江，可以发现转至这个界面，最后是在XHR的包中，通过这样子我们可以获取这些包的URL信息，并且可以通过Python模拟这个过程。

![1557316201601](D:\typora\1557316201601.png)

下面是获取产品的Url，其中由于服务器不能识别中文字符，所以使用Utf-8编码。

https://touch.dujia.qunar.com/list?modules=list%2CbookingInfo%2CactivityDetail&dep=%E6%9D%AD%E5%B7%9E&query=%E4%B8%BD%E6%B1%9F%E8%87%AA%E7%94%B1%E8%A1%8C&dappDealTrace=true&mobFunction=%E6%89%A9%E5%B1%95%E8%87%AA%E7%94%B1%E8%A1%8C&cfrom=zyx&it=dujia_hy_destination&date=&needNoResult=true&originalquery=%E4%B8%BD%E6%B1%9F&limit=8,32&qsact=scroll

​	下面是解码后的结果，可以发现，需要获取的信息包括出发城市名称和目的地城市名称。

![1557316549345](D:\typora\1557316549345.png)

​	**步骤4.**所以我们还需要获取城市名称的数据，通过点击框框图片，可以转到如下界面

![1557318790786](D:\typora\1557318790786.png)

![1557318827947](D:\typora\1557318827947.png)

​	可以看见信息位于depCities,qunar包中，至此我们可以总结一下我们爬取流程。

​	URL = https://touch.dujia.qunar.com/depCities.qunar

![1557318860320](D:\typora\1557318860320.png)

###### 3.1.3 爬取流程总结

​	**1.获取城市信息**

​		由于搜索产品信息的URL需要提供城市信息，所以首先我们需要获取城市信息，获取出发地

​	**2.指定出发地获取目的地信息**

​		由于我们指定了出发地点，所以通过步骤2中获取的URL中，传入目的地信息，获取目的地信息。

​	**3.通过目的地信息和出发地信息获取产品信息**

​		将参数传入步骤3的URL中，可以获取由出发地到目的地所有的产品信息，进而获取产品信息。

​	**4.通过建立MongoDB链接，存储数据**

##### 3.2 爬取信息流程

​	1.获取出发点信息

​	由步骤4可以看到，我们可以通过查看depCities,qunar包的Header查看信息，可以看到使用get方法获取信息

![1557401012327](D:\typora\1557401012327.png)

```python
import requests
# 步骤4中的URL
url = "https://touch.dujia.qunar.com/depCities.qunar"
strhtml = requests.get(url)
dep_dict = strhtml.json()

for dep_item in dep_dict['data']:
    for dep in dep_dict['data'][dep_item]:
        print(dep)	# dep为城市名称
```

​	2.获取目的地信息

​	由步骤2可以看到，可以通过输入出发地信息获取目的地信息

```python
import requests
import urllib
import time
url = "https://touch.dujia.qunar.com/depCities.qunar"
strhtml = requests.get(url)
dep_dict = strhtml.json()
for dep_item in dep_dict['data']:
    for dep in dep_dict['data'][dep_item]:
        print(dep)	# dep为城市名称
        # 下面为获取目的地信息,使用urllib将出发地信息解码
        a = []
        # 步骤2中的URL
        url = "https://touch.dujia.qunar.com/golfz/sight/arriveRecommend?" \
              "dep={}&exclude=&extensionImg=255,175".format(urllib.request.quote(dep))
        time.sleep(1)
        strhtml = requests.get(url)
        arrive_dict = strhtml.json()
        for arr_item in arrive_dict['data']:
            for arr_item_1 in arr_item['subModules']:
                for query in arr_item_1['items']:
                    print(query['query'])
                    # 由于会存在重复的情况，所以需要去重
                    if query['query'] not in a:
                        a.append(query['query'])
```

​	3.通过出发地和目的地信息获取产品信息

​	现在我们已经获取了出发地和目的地信息，就要通过步骤3的信息获取产品信息。

```Python
import requests
import urllib
import time

client = pymongo.MongoClient('localhost', 27017)
# 在MongoDB中新建名为weather的数据库
book_qunar = client['qunar']
sheet_qunar_zyx = book_qunar['quunar_zyx']

url = "https://touch.dujia.qunar.com/depCities.qunar"
strhtml = requests.get(url)
dep_dict = strhtml.json()
for dep_item in dep_dict['data']:
    for dep in dep_dict['data'][dep_item]:
        print(dep)	# dep为城市名称
        # 下面为获取目的地信息,使用urllib将出发地信息解码
        a = []
        # 步骤2中的URL
        url = "https://touch.dujia.qunar.com/golfz/sight/arriveRecommend?dep={}&exclude=&extensionImg=255,175".format(urllib.request.quote(dep))
        time.sleep(1)
        strhtml = requests.get(url)
        arrive_dict = strhtml.json()
        for arr_item in arrive_dict['data']:
            for arr_item_1 in arr_item['subModules']:
                for query in arr_item_1['items']:
                    print(query['query'])
                    # 由于会存在重复的情况，所以需要去重
                    if query['query'] not in a:
                        a.append(query['query'])
         for item in a：
        	# 这个是步骤3的URL，其中有需要参数的位置都已经用{}标了出来
        	url = "https://touch.dujia.qunar.com/list?modules=list%2CbookingInfo%2CactivityDetail&dep={}&query={}&dappDealTrace=true&mobFunction=%E6%89%A9%E5%B1%95%E8%87%AA%E7%94%B1%E8%A1%8C&cfrom=zyx&it=dujia_hy_destination&date=&needNoResult=true&originalquery={}&limit=0,32&includeAD=true&qsact=search".format(urllib.request.quote(dep),urllib.request.quote(item),urllib.request.quote(item))
            time.sleep(1)
            strhtml = requests.get(url)
            # 这里会出现爬去到的信息为"您的访问不合法，请联系技术人员"的错误
            # 下面会通过cookies解决，将cookies重新给get则可以获得正确数据
            cookies = requests.utils.dict_from_cookiejar(strhtml.cookies)
        	strhtml = requests.get(url, cookies=cookies)
            # routeCount表示根据当前出发地和目的地的信息返回的产品数量
            routeCount = int(strhtml.json()['data']['limit']['routeCount'])
			# 这里由于网页中没有出现全部信息，需要动态的获取，传入的参数是limit,所以为了爬取一下信息，需要再一次进行处理
            for limit in range(0, routeCount, 20):
                url = "https://touch.dujia.qunar.com/list?modules=list%2CbookingInfo%2CactivityDetail&dep={}&query={}&dappDealTrace=true&mobFunction=%E6%89%A9%E5%B1%95%E8%87%AA%E7%94%B1%E8%A1%8C&cfrom=zyx&it=dujia_hy_destination&date=&needNoResult=true&originalquery={}&limit{},32&includeAD=true&qsact=search".format(urllib.request.quote(dep),urllib.request.quote(item),urllib.request.quote(item), limit)
                time.sleep(1)
                strhtml = requests.get(url)
                cookies = requests.utils.dict_from_cookiejar(strhtml.cookies)
                strhtml = requests.get(url, cookies=cookies)
                # 这里就把包含20个数据的产品信息获取到了
                print(strhtml.json())
                # 增加索引信息存放至MongoDB数据库中。
                result = {
                    'date': time.strftime('%Y-%m-%d', time.localtime(time.time())),
                    'dep': dep,
                    'arrive': item,
                    'limit': limit,
                    'result': strhtml.json()
        				}
        		sheet_qunar_zyx.insert_one(result)
```

##### 3.3 问题总结

​	以上爬取信息过程中遇到的一些问题的总结

​	**1.问题:提示爬取的信息为"您的访问不合法，请联系技术人员"**

​	[解决方法](<https://blog.csdn.net/shu15121856/article/details/83865181>)，使用cookies

​	**2.对于动态信息的获取，**

​		因为动态信息不会改变URL，所以只能通过抓包软件获取动态信息的包，并从包中获取改变的参数信息，并在python中传入参数模拟请求的过程。



